{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Base path where your files are located\n",
    "base_path = '/Users/maushariff/Downloads/Local_Disk_E/Byrav/Internet2_Data/Atla'\n",
    "\n",
    "# List all files in the directory\n",
    "file_names = os.listdir(base_path)\n",
    "\n",
    "# Generate full paths to the files\n",
    "file_paths = [os.path.join(base_path, file_name) for file_name in file_names]\n",
    "\n",
    "# Print the file paths (or use them for further processing)\n",
    "# for path in file_paths:\n",
    "#     print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop through the files, read them, and combine the data\n",
    "# Load each file, handle JSON parsing, and append the resulting DataFrame to the list\n",
    "for file_path in file_paths:\n",
    "    data_list = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                # Append each valid JSON object to the list\n",
    "                data_list.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON on this line: {line}\")\n",
    "                print(e)\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one large DataFrame\n",
    "combined_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined DataFrame to a Parquet file (you can change it to Pickle if you prefer)\n",
    "output_parquet_path = os.path.join(base_path, 'combined_internet_traffic_data.parquet')\n",
    "combined_df.to_parquet(output_parquet_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   export_sysid                  t_first                   t_last  proto  \\\n",
      "0             6  2021-11-04T00:00:15.104  2021-11-04T00:02:46.400     17   \n",
      "1            56  2021-11-04T00:04:45.696  2021-11-04T00:04:45.696     17   \n",
      "2             9  2021-11-04T00:04:14.720  2021-11-04T00:04:14.720      6   \n",
      "3             4  2021-11-04T00:01:33.952  2021-11-04T00:01:34.720      6   \n",
      "4             1  2021-11-04T00:02:49.728  2021-11-04T00:02:49.728     17   \n",
      "\n",
      "       src4_addr      dst4_addr  src_port  dst_port  src_tos  dst_tos  ...  \\\n",
      "0     165.91.8.0   149.137.72.0     45587      8801      184        0  ...   \n",
      "1  143.215.192.0    198.71.40.0      9097      6151        0        0  ...   \n",
      "2    52.216.88.0  146.226.136.0       443     53446        0        0  ...   \n",
      "3  128.118.184.0   139.229.96.0     54262        80        0        0  ...   \n",
      "4   173.231.80.0   131.94.184.0      8801     12614        0        0  ...   \n",
      "\n",
      "   output_snmp  src_as  dst_as  src_mask  dst_mask   ip4_next_hop  \\\n",
      "0         1107    3794   30103        16        24    198.71.45.7   \n",
      "1          853    2637   11537        16        31   198.71.46.64   \n",
      "2          875   16509   20243        24        18  162.252.70.43   \n",
      "3          875    3999   19226        16        16  162.252.70.43   \n",
      "4          875   30103    3681        24        16  162.252.70.43   \n",
      "\n",
      "     ip4_router src6_addr dst6_addr ip6_next_hop  \n",
      "0  64.57.28.243      None      None         None  \n",
      "1  64.57.28.243      None      None         None  \n",
      "2  64.57.28.243      None      None         None  \n",
      "3  64.57.28.243      None      None         None  \n",
      "4  64.57.28.243      None      None         None  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To reload the combined data later\n",
    "df_combined_parquet = pd.read_parquet(output_parquet_path)\n",
    "print(df_combined_parquet.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
